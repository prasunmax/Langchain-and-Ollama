{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcement-on-ML\n",
    "<a href='http://www.kgptalkie.com' target=\"_blank\"> <img src='https://github.com/laxmimerit/Important-Announcement-on-ML/raw/master/kgptalkie_strips.png'/></a>\n",
    "\n",
    "# ML Resources\n",
    "|  ML Course | Description |\n",
    "|:---|:---|\n",
    "| [**Deploy LLM App with Ollama and Langchain in Production**](https://www.udemy.com/course/ollama-and-langchain/?referralCode=7F4C0C7B8CF223BA9327) | Master Langchain v0.3, Private Chatbot, Deploy LLM App.  Ollama, LLAMA, LLAMA 3.2, FAISS, RAG, Deploy RAG, Gen AI, LLM|\n",
    "| [**Fine Tuning LLM with HuggingFace Transformers for NLP**](https://www.udemy.com/course/fine-tuning-llm-with-hugging-face-transformers/?referralCode=6DEB3BE17C2644422D8E) | Learn how to fine tune LLM with custom dataset. You will learn basics of transformers then fine tune LLM|\n",
    "| [**Data Visualization in Python Masterclassâ„¢: Beginners to Pro**](https://bit.ly/udemy95off_kgptalkie) |  Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Python for Machine Learning: A Step-by-Step Guide**](https://bit.ly/ml-ds-project) | Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Deep Learning for Beginners with Python**](https://bit.ly/dl-with-python) | Neural Networks, TensorFlow, ANN, CNN, RNN, LSTM, Transfer Learning and Much More. |\n",
    "| [**Python for Linear Regression in Machine Learning**](https://bit.ly/regression-python) | Learn to build Linear Regression models using Python and its libraries like Scikit-Learn. |\n",
    "| [**Introduction to Spacy 3 for Natural Language Processing**](https://bit.ly/spacy-intro) | Learn to build Natural Language Processing models using Python and its libraries like Spacy. |\n",
    "| [**Advanced Machine Learning and Deep Learning Projects**](https://bit.ly/kgptalkie_ml_projects) | Learn to build Advanced Machine Learning and Deep Learning models using Python and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Natural Language Processing in Python for Beginners**](https://bit.ly/intro_nlp) | Learn to build Natural Language Processing Projects using Spacy, NLTK, and Gensim, and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Deployment of Machine Learning Models in Production in Python**](https://bit.ly/bert_nlp) |  Learn to deploy Machine Learning and Deep Learning models using Python and its libraries like Flask, Streamlit, and NGINX. |\n",
    "| [**R 4.0 Programming for Data Science - Beginners to Pro**](https://bit.ly/r4-ml) | Learn to build Machine Learning and Deep Learning models using R and its libraries like caret, tidyverse, and keras. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microsoft Office Files PPT Excel and Word Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note:**\n",
    "Unstructured Data Reader Setup\n",
    "\n",
    "https://python.langchain.com/docs/integrations/providers/unstructured/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 1: Key Notes and Script Generation for PPT Presentor (Speaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "OSError: No such file or directory: 'C:\\Users\\laxmi\\AppData\\Roaming\\nltk_data\\tokenizers\\punkt\\PY3_tab'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Handling:\n",
    "C:\\Users\\laxmi\\AppData\\Roaming\\nltk_data\\tokenizers\\punkt --> PY3 to PY3_tab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:27:48.659026Z",
     "start_time": "2025-01-26T04:27:48.477544Z"
    }
   },
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /mnt/v/linuxHome/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:28:30.471394Z",
     "start_time": "2025-01-26T04:28:29.593590Z"
    }
   },
   "source": [
    "# !pip install unstructured openpyxl python-magic python-pptx\n",
    "# !pip install \"unstructured[all-docs]\""
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/mnt/v/linuxHome/.local/bin/pip\", line 5, in <module>\r\n",
      "    from pip._internal.cli.main import main\r\n",
      "ModuleNotFoundError: No module named 'pip'\r\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/mnt/v/linuxHome/.local/bin/pip\", line 5, in <module>\r\n",
      "    from pip._internal.cli.main import main\r\n",
      "ModuleNotFoundError: No module named 'pip'\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:31:45.402066Z",
     "start_time": "2025-01-26T04:31:30.687136Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "\n",
    "loader = UnstructuredPowerPointLoader(\"data/ml_course.pptx\", mode=\"elements\")\n",
    "\n",
    "docs = loader.load()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:32:12.630457Z",
     "start_time": "2025-01-26T04:32:12.627950Z"
    }
   },
   "source": [
    "doc = docs[0]\n",
    "print(doc.metadata)\n",
    "print(doc.page_content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'data/ml_course.pptx', 'category_depth': 0, 'file_directory': 'data', 'filename': 'ml_course.pptx', 'last_modified': '2025-01-16T02:24:28', 'page_number': 1, 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.presentationml.presentation', 'category': 'Title', 'element_id': '1378fc8ea4dd0830a3c5f93e9d31a516'}\n",
      "Machine Learning Model Deployment\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:32:23.524976Z",
     "start_time": "2025-01-26T04:32:23.522154Z"
    }
   },
   "source": [
    "ppt_data = {}\n",
    "for doc in docs:\n",
    "    page = doc.metadata[\"page_number\"]\n",
    "    ppt_data[page] = ppt_data.get(page, \"\")  + \"\\n\\n\" + doc.page_content"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:32:32.079121Z",
     "start_time": "2025-01-26T04:32:32.075935Z"
    }
   },
   "source": [
    "ppt_data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '\\n\\nMachine Learning Model Deployment\\n\\nIntroduction to ML Pipeline\\n\\nhttps://bit.ly/bert_nlp\\n\\n',\n",
       " 2: '\\n\\nWhat is Machine Learning Pipeline?\\n\\n',\n",
       " 3: '\\n\\nType of ML Deployment\\n\\nBatch: In batch deployment, ML models process large volumes of data at scheduled intervals, ideal for tasks like end-of-day reporting or monthly analytics.\\n\\nStream: Stream deployment enables ML models to process and analyze data in real-time as it flows in, suitable for applications like fraud detection or live social media analysis.\\n\\nRealtime: Realtime deployment allows ML models to provide instant predictions or decisions in response to incoming data, essential for use cases like recommendation systems or autonomous driving.\\n\\nEdge: Edge deployment involves running ML models on local devices close to the data source, reducing latency and bandwidth usage, which is crucial for IoT applications and smart devices.\\n\\n',\n",
       " 4: '\\n\\nInfrastructure and Integration\\n\\nHardware and Software: Setting up the right environment for model deployment.\\n\\nIntegration: Seamlessly integrating the model with existing systems and applications.\\n\\n',\n",
       " 5: '\\n\\nBenefits of Deploying ML Models\\n\\nFocus on new models, not maintaining existing models || Prevention of bugs || Creation of records for debugging and reproducing results || Standardization || Allows models to handle real-time data and large user bases.\\n\\n',\n",
       " 6: '\\n\\nChallenges in ML Deployment\\n\\nData Management: Making sure the model gets the right kind of data.\\n\\nModel Scalability and Performance: Ensuring that their model can effectively scale as it keeps adding more complex information.\\n\\nIntegration with Existing Systems: Fitting the model into current computers and software.\\n\\nMonitoring and Maintenance: Watching and fixing the model over time.\\n\\nSecurity and Privacy: Protecting data and keeping it private.\\n\\nResource Management: Using computer resources like memory and power wisely.\\n\\nVersioning and Model Management: Keeping track of different versions of the model.\\n\\nRegulatory Compliance: Making sure the model follows the laws, rules, and regulations.\\n\\nUser Acceptance and Trust: Getting people to trust and accept the model.\\n\\nExplainability and Transparency: Being able to explain how the model works.\\n\\nCost Management: Managing how much it costs to use the model.\\n\\nAs per research, only 13% of ML models ever make it to production. This is a huge gap, considering the possibilities that AI model deployment can bring to the organization.\\n\\n',\n",
       " 7: '\\n\\nData and Model Management\\n\\nData Pipelines: Building and maintaining data pipelines for continuous data flow.\\n\\nModel Versioning: Tracking and managing different versions of models.\\n\\n',\n",
       " 8: '\\n\\nA/B Testing\\n\\nObjective Comparison: A/B testing allows for an objective comparison of two model versions to determine which performs better based on specific metrics.\\n\\nReal-World Application: It is widely used to optimize user experiences, such as testing different recommendation systems or ad strategies to enhance engagement or conversion rates.\\n\\nStatistical Significance: The technique ensures that performance differences are statistically significant and not due to random chance by using control and treatment groups along with statistical tests.\\n\\n',\n",
       " 9: '\\n\\nSecurity, Compliance and Bias\\n\\nSecurity: Ensuring the security of machine learning models involves protecting sensitive data from unauthorized access and breaches through robust encryption, secure APIs, and access controls\\n\\nCompliance: Adhering to industry regulations and standards, such as GDPR or HIPAA, is critical to ensure the legal and ethical use of data in machine learning deployments. This involves data anonymization, user consent, and regular compliance audits.\\n\\nBias Detection: Identifying and mitigating bias in ML models is crucial to prevent unfair and discriminatory outcomes. This involves using diverse training datasets, applying fairness-aware algorithms, and conducting bias impact assessments\\n\\nContinuous Monitoring: Regular monitoring and updating of deployed models are essential to maintain security, compliance, and fairness. This involves real-time performance tracking, automated alerts for anomalies, and periodic model retraining.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:34:03.388931Z",
     "start_time": "2025-01-26T04:34:03.386362Z"
    }
   },
   "source": [
    "context = \"\"\n",
    "for page, content in ppt_data.items():\n",
    "    context += f\"### Slide {page}:\\n\\n{content.strip()}\\n\\n\\n\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:34:14.799080Z",
     "start_time": "2025-01-26T04:34:14.796732Z"
    }
   },
   "source": "print(context)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Slide 1:\n",
      "\n",
      "Machine Learning Model Deployment\n",
      "\n",
      "Introduction to ML Pipeline\n",
      "\n",
      "https://bit.ly/bert_nlp\n",
      "\n",
      "\n",
      "### Slide 2:\n",
      "\n",
      "What is Machine Learning Pipeline?\n",
      "\n",
      "\n",
      "### Slide 3:\n",
      "\n",
      "Type of ML Deployment\n",
      "\n",
      "Batch: In batch deployment, ML models process large volumes of data at scheduled intervals, ideal for tasks like end-of-day reporting or monthly analytics.\n",
      "\n",
      "Stream: Stream deployment enables ML models to process and analyze data in real-time as it flows in, suitable for applications like fraud detection or live social media analysis.\n",
      "\n",
      "Realtime: Realtime deployment allows ML models to provide instant predictions or decisions in response to incoming data, essential for use cases like recommendation systems or autonomous driving.\n",
      "\n",
      "Edge: Edge deployment involves running ML models on local devices close to the data source, reducing latency and bandwidth usage, which is crucial for IoT applications and smart devices.\n",
      "\n",
      "\n",
      "### Slide 4:\n",
      "\n",
      "Infrastructure and Integration\n",
      "\n",
      "Hardware and Software: Setting up the right environment for model deployment.\n",
      "\n",
      "Integration: Seamlessly integrating the model with existing systems and applications.\n",
      "\n",
      "\n",
      "### Slide 5:\n",
      "\n",
      "Benefits of Deploying ML Models\n",
      "\n",
      "Focus on new models, not maintaining existing models || Prevention of bugs || Creation of records for debugging and reproducing results || Standardization || Allows models to handle real-time data and large user bases.\n",
      "\n",
      "\n",
      "### Slide 6:\n",
      "\n",
      "Challenges in ML Deployment\n",
      "\n",
      "Data Management: Making sure the model gets the right kind of data.\n",
      "\n",
      "Model Scalability and Performance: Ensuring that their model can effectively scale as it keeps adding more complex information.\n",
      "\n",
      "Integration with Existing Systems: Fitting the model into current computers and software.\n",
      "\n",
      "Monitoring and Maintenance: Watching and fixing the model over time.\n",
      "\n",
      "Security and Privacy: Protecting data and keeping it private.\n",
      "\n",
      "Resource Management: Using computer resources like memory and power wisely.\n",
      "\n",
      "Versioning and Model Management: Keeping track of different versions of the model.\n",
      "\n",
      "Regulatory Compliance: Making sure the model follows the laws, rules, and regulations.\n",
      "\n",
      "User Acceptance and Trust: Getting people to trust and accept the model.\n",
      "\n",
      "Explainability and Transparency: Being able to explain how the model works.\n",
      "\n",
      "Cost Management: Managing how much it costs to use the model.\n",
      "\n",
      "As per research, only 13% of ML models ever make it to production. This is a huge gap, considering the possibilities that AI model deployment can bring to the organization.\n",
      "\n",
      "\n",
      "### Slide 7:\n",
      "\n",
      "Data and Model Management\n",
      "\n",
      "Data Pipelines: Building and maintaining data pipelines for continuous data flow.\n",
      "\n",
      "Model Versioning: Tracking and managing different versions of models.\n",
      "\n",
      "\n",
      "### Slide 8:\n",
      "\n",
      "A/B Testing\n",
      "\n",
      "Objective Comparison: A/B testing allows for an objective comparison of two model versions to determine which performs better based on specific metrics.\n",
      "\n",
      "Real-World Application: It is widely used to optimize user experiences, such as testing different recommendation systems or ad strategies to enhance engagement or conversion rates.\n",
      "\n",
      "Statistical Significance: The technique ensures that performance differences are statistically significant and not due to random chance by using control and treatment groups along with statistical tests.\n",
      "\n",
      "\n",
      "### Slide 9:\n",
      "\n",
      "Security, Compliance and Bias\n",
      "\n",
      "Security: Ensuring the security of machine learning models involves protecting sensitive data from unauthorized access and breaches through robust encryption, secure APIs, and access controls\n",
      "\n",
      "Compliance: Adhering to industry regulations and standards, such as GDPR or HIPAA, is critical to ensure the legal and ethical use of data in machine learning deployments. This involves data anonymization, user consent, and regular compliance audits.\n",
      "\n",
      "Bias Detection: Identifying and mitigating bias in ML models is crucial to prevent unfair and discriminatory outcomes. This involves using diverse training datasets, applying fairness-aware algorithms, and conducting bias impact assessments\n",
      "\n",
      "Continuous Monitoring: Regular monitoring and updating of deployed models are essential to maintain security, compliance, and fairness. This involves real-time performance tracking, automated alerts for anomalies, and periodic model retraining.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:36:41.503030Z",
     "start_time": "2025-01-26T04:36:40.914942Z"
    }
   },
   "source": [
    "### LLM Code\n",
    "from scripts import llm"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:38:06.870463Z",
     "start_time": "2025-01-26T04:37:34.420654Z"
    }
   },
   "source": [
    "question =\"\"\"\n",
    "For each PowerPoint slide provided above, write a 2-minute script that effectively conveys the key points.\n",
    "Ensure a smooth flow between slides, maintaining a clear and engaging narrative.\n",
    "\"\"\"\n",
    "\n",
    "response = llm.ask_llm(context, question)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:38:11.239656Z",
     "start_time": "2025-01-26T04:38:11.235533Z"
    }
   },
   "source": [
    "# print(response)\n",
    "with open(\"data/ppt_script.md\", \"w\") as f:\n",
    "    f.write(response)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 2: Excel Data Analysis with LLM \n",
    "**Note:** Currently LLMs are not good in Math and Data Analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:40:40.081788Z",
     "start_time": "2025-01-26T04:40:40.069208Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import  UnstructuredExcelLoader"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:40:52.026004Z",
     "start_time": "2025-01-26T04:40:49.691586Z"
    }
   },
   "source": [
    "loader = UnstructuredExcelLoader(\"data/sample.xlsx\",  mode=\"elements\")\n",
    "docs = loader.load()\n",
    "\n",
    "len(docs)\n",
    "\n",
    "doc = docs[0]\n",
    "doc.metadata\n",
    "\n",
    "doc.page_content\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Name Last Name City Gender Brandon James Miami M Sean Hawkins Denver M Judy Day Los Angeles F Ashley Ruiz San Francisco F Stephanie Gomez Portland F'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:40:58.333595Z",
     "start_time": "2025-01-26T04:40:58.331280Z"
    }
   },
   "source": [
    "context = doc.metadata['text_as_html']"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:41:01.109272Z",
     "start_time": "2025-01-26T04:41:01.106274Z"
    }
   },
   "source": [
    "context"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table><tr><td>First Name</td><td>Last Name</td><td>City</td><td>Gender</td></tr><tr><td>Brandon</td><td>James</td><td>Miami</td><td>M</td></tr><tr><td>Sean</td><td>Hawkins</td><td>Denver</td><td>M</td></tr><tr><td>Judy</td><td>Day</td><td>Los Angeles</td><td>F</td></tr><tr><td>Ashley</td><td>Ruiz</td><td>San Francisco</td><td>F</td></tr><tr><td>Stephanie</td><td>Gomez</td><td>Portland</td><td>F</td></tr></table>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:41:36.789727Z",
     "start_time": "2025-01-26T04:41:34.864058Z"
    }
   },
   "source": [
    "question = \"Return this data in Markdown format.\"\n",
    "response = llm.ask_llm(context, question)\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| First Name | Last Name | City | Gender |\n",
      "|------------|-----------|-------|--------|\n",
      "| Brandon    | James     | Miami | M      |\n",
      "| Sean       | Hawkins   | Denver | M      |\n",
      "| Judy       | Day       | Los Angeles | F      |\n",
      "| Ashley     | Ruiz      | San Francisco | F      |\n",
      "| Stephanie  | Gomez     | Portland   | F      |\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:43:15.576787Z",
     "start_time": "2025-01-26T04:43:14.065827Z"
    }
   },
   "source": [
    "question = \"Return all entries in the table where Gender is 'F'. Format the response in Markdown. Do not write preambles and explanation.\"\n",
    "response = llm.ask_llm(context, question)\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| First Name | Last Name | City | Gender |\n",
      "|------------|-----------|-------|--------|\n",
      "| Judy       | Day       | Los Angeles   | F      |\n",
      "| Ashley     | Ruiz      | San Francisco | F      |\n",
      "| Stephanie  | Gomez     | Portland    | F      |\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:43:49.512129Z",
     "start_time": "2025-01-26T04:43:48.380810Z"
    }
   },
   "source": [
    "question = \"Return all entris in the table where Gender is 'male'. Format the response in Markdown. Do not write preambles and explanation.\"\n",
    "response = llm.ask_llm(context, question)\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| First Name | Last Name | City    | Gender |\n",
      "|------------|-----------|---------|--------|\n",
      "| Brandon    | James     | Miami   | M      |\n",
      "| Sean       | Hawkins   | Denver   | M      |\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 3: Personalized Job Application Letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in c:\\users\\laxmi\\anaconda3\\envs\\ml\\lib\\site-packages (0.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The value specified in an AutoRun registry key could not be parsed.\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:45:12.980319Z",
     "start_time": "2025-01-26T04:45:12.951437Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders import  Docx2txtLoader\n",
    "\n",
    "loader = Docx2txtLoader(\"data/job_description.docx\")\n",
    "\n",
    "docs = loader.load()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:45:16.312463Z",
     "start_time": "2025-01-26T04:45:16.309971Z"
    }
   },
   "source": [
    "context = docs[0].page_content"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:45:22.338733Z",
     "start_time": "2025-01-26T04:45:22.336111Z"
    }
   },
   "source": "print(context)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Description - Data Scientist\n",
      "\n",
      "At SpiceJet, we rely on data to provide us valuable insights, and to automate our systems and solutions to help us increase revenues, reduce costs and provide improved customer experiences. We are seeking an experienced data scientist to deliver insights and automate our systems and processes. Ideal team member will have mathematical and statistical expertise, experience with modern data science programming languages and machine learning/AI platforms and techniques. You will mine, clean and interpret our data and then develop machine learning models to deliver business value across different parts of the business. \n",
      "\n",
      "Objectives of this Role\n",
      "\n",
      "Use Data Science and Machine Learning to increase revenue, reduce costs and increase customer satisfaction.\n",
      "\n",
      "Collaborate with product design and engineering to develop an understanding of needs\n",
      "\n",
      "Understand where the required data resides and work on ways to extract the relevant data.\n",
      "\n",
      "Research and devise statistical and machine learning models.\n",
      "\n",
      "Communicate insights to stakeholders in an automated fashion to enable them to take business decisions.\n",
      "\n",
      "Deploy models in production to automate various processes.\n",
      "\n",
      "\n",
      "\n",
      "Skills and Qualifications\n",
      "\n",
      "Bachelorâ€™s degree in Data Science, Computer Science, Statistics, Applied mathematics, or related discipline\n",
      "\n",
      "3+ years experience in data science\n",
      "\n",
      "Proficiency with Machine Learning platforms and techniques, data mining, mathematics, and statistical analysis\n",
      "\n",
      "Predictive modelling experience\n",
      "\n",
      "Experience with Python, R, Excel, Tableau, SQL\n",
      "\n",
      "Comfortable working in a dynamic, research-oriented group with several ongoing concurrent projects\n",
      "\n",
      "\n",
      "\n",
      "Preferred Qualifications\n",
      "\n",
      "Masterâ€™s degree in Data Science, Computer Science, Stats, Applied math, or related discipline\n",
      "\n",
      "2+ years of project management experience\n",
      "\n",
      "\n",
      "\n",
      "Competencies:\n",
      "\n",
      "Defining: Can translate fuzzy problem in assigned area into formalized structure\n",
      "\n",
      "Troubleshooting: Can troubleshoot unseen problems in assigned area\n",
      "\n",
      "Solutioning:  Can independently implement the solution\n",
      "\n",
      "Coding Principles: Extensability, Abstraction, Separation of concerns, Chooses right Data Science/Machine learning techniques.\n",
      "\n",
      "Coding Quality: Performant, Integration tests coverage, implements security requirements.\n",
      "\n",
      "Programming Language Proficiency: Usage of design patterns and knowledge of functional aspects.\n",
      "\n",
      "Project Management: Can break down tasks, identify dependencies and provide accurate effort estimates that feed into the larger plan. Proactively resolve dependencies and communicate around progress and blockers.\n",
      "\n",
      "Execution: Responsible for timely completion of assigned components including integration and deployment to appropriate environments. Complete ownership of quality including iterations with stakeholders to meet the desired objectives.\n",
      "\n",
      "Responsiveness: Understands team priorities. Own, identify and quick turn around for production issues that address the root cause.\n",
      "\n",
      "Designing: Low level design, functional modeling, Adaptability, High level design with guidance\n",
      "\n",
      "Analysis: Understanding impact of design changes\n",
      "\n",
      "Non Functional Attributes: Understands the basic concepts around performance and can contribute to measuring and improving performance. Understands scalability\n",
      "\n",
      "Data Orientation: Apply algorithms to make smarter and intelligent data driven systems, Good understanding and know hows of various data tools/tech (e.g. Data Tools, IR and ML tools)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T04:45:36.913968Z",
     "start_time": "2025-01-26T04:45:31.455056Z"
    }
   },
   "source": [
    "question =\"\"\"\n",
    "My name is Aaditya, and I am a recent graduate from IIT with a focus on Natural Language Processing and Machine Learning.\n",
    "I am applying for a Data Scientist position at SpiceJet.\n",
    "Please write a concise job application email for me in short, removing any placeholders, including references to job boards or sources.\n",
    "\"\"\"\n",
    "response = llm.ask_llm(context, question)\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Data Scientist Position at SpiceJet\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am excited to apply for the Data Scientist position at SpiceJet. With a strong academic background in Natural Language Processing and Machine Learning from IIT, I am confident that my skills and experience make me an ideal candidate for this role.\n",
      "\n",
      "As a recent graduate with expertise in machine learning and NLP, I possess a solid foundation in mathematical and statistical concepts, programming languages such as Python, R, and SQL, and experience with data mining, machine learning platforms and techniques. My proficiency in these areas will enable me to effectively mine, clean, and interpret your data, develop machine learning models, and deliver business value across different parts of the business.\n",
      "\n",
      "I am particularly drawn to this role because of the opportunity to collaborate with product design and engineering to develop understanding of needs, research and devise statistical and machine learning models, and deploy models in production to automate various processes. I am excited about the prospect of working with a dynamic team to drive revenue growth, reduce costs, and enhance customer satisfaction.\n",
      "\n",
      "I have attached my resume for your review. Thank you for considering my application. I look forward to discussing how my skills and experience can contribute to SpiceJet's success.\n",
      "\n",
      "Best regards,\n",
      "Aaditya\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
